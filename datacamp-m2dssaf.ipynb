{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14774,"databundleVersionId":875431,"sourceType":"competition"}],"dockerImageVersionId":30152,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/plmazt/datacamp-m2dssaf-catapulte?scriptVersionId=162974773\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Introduction : Librairies, Data & Processing","metadata":{}},{"cell_type":"markdown","source":"## Import de libraries","metadata":{}},{"cell_type":"code","source":"import os # data importation\n\n# data structure/handling\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt # ploting\nimport cv2 # image visualisation\nfrom PIL import Image\n\n# Histogramme\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-04-19T02:13:33.94893Z","iopub.execute_input":"2022-04-19T02:13:33.949396Z","iopub.status.idle":"2022-04-19T02:13:33.954439Z","shell.execute_reply.started":"2022-04-19T02:13:33.949358Z","shell.execute_reply":"2022-04-19T02:13:33.953512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import des données","metadata":{}},{"cell_type":"code","source":"root = \"/kaggle/input/aptos2019-blindness-detection\"\n\ntrain = pd.read_csv(os.path.join(root, 'train.csv')).drop_duplicates()\ntest = pd.read_csv(os.path.join(root, 'test.csv')).drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2022-04-19T00:20:41.265383Z","iopub.execute_input":"2022-04-19T00:20:41.266038Z","iopub.status.idle":"2022-04-19T00:20:41.299605Z","shell.execute_reply.started":"2022-04-19T00:20:41.265999Z","shell.execute_reply":"2022-04-19T00:20:41.298668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Processing : Recadrage","metadata":{}},{"cell_type":"code","source":"def remove_black(img,tol=7):\n    # si l'image est en noir et blanc\n    if img.ndim==2:\n        mask = img>tol\n        # mask.any(0) = vérifie la présence d'une valeur True sur chaque colonne\n        # mask.any(1) = vérifie la présence d'une valeur True sur chaque ligne\n        # on sélectionne les lignes et les colonnes où il y a au moins une valeur True\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    \n    # si l'image est en couleur\n    elif img.ndim==3:\n        # transforme l'image en noir et blanc\n        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        \n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape\n        \n        # vérifie que l'image renvoyée contient au moins un pixel\n        if (check_shape == (0,0)):\n            return img\n        else:\n            # mask.any(0) = vérifie la présence d'une valeur True sur chaque colonne\n            # mask.any(1) = vérifie la présence d'une valeur True sur chaque ligne\n            # on sélectionne les lignes et les colonnes où il y a au moins une valeur True\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n            img = np.stack([img1,img2,img3],axis=-1)\n        return img","metadata":{"execution":{"iopub.status.busy":"2022-04-19T00:21:26.797751Z","iopub.execute_input":"2022-04-19T00:21:26.798062Z","iopub.status.idle":"2022-04-19T00:21:26.809389Z","shell.execute_reply.started":"2022-04-19T00:21:26.798024Z","shell.execute_reply":"2022-04-19T00:21:26.808547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Déséquilibre de classes & Data augmentation","metadata":{}},{"cell_type":"markdown","source":"## Déséquilibre de classes","metadata":{}},{"cell_type":"code","source":"# Pie Chart\neff = list()\npercentage = list()\nfor i in range(5):\n    eff.append(len(train.iloc[np.where(train.iloc[:,1] == i)]))\n    percentage.append(round(100 * len(train.iloc[np.where(train.iloc[:,1] == i)]) / 3662))\npalette = sns.color_palette('hls', n_colors = 5)\n# Pie Chart\nplt.pie(eff, labels = ['0', '1', '2', '3', '4'], autopct = '%1.0f%%', colors = palette)\nplt.title('Proportion des différents stades de la maladie')","metadata":{"execution":{"iopub.status.busy":"2022-04-19T00:21:42.399268Z","iopub.execute_input":"2022-04-19T00:21:42.403403Z","iopub.status.idle":"2022-04-19T00:21:42.843574Z","shell.execute_reply.started":"2022-04-19T00:21:42.403354Z","shell.execute_reply":"2022-04-19T00:21:42.842699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data augmentation","metadata":{}},{"cell_type":"code","source":"#Importing torch\nimport torch\nfrom torch.utils.data import WeightedRandomSampler\n\nsize_data_augmented = 6000\n\ntargets = train['diagnosis'].values\nclass_sample_count = np.unique(targets, return_counts=True)[1]\nweight = 1. / class_sample_count\nsamples_weight = weight[targets]\nsamples_weight = torch.from_numpy(samples_weight).double()\naugmented_sampler = WeightedRandomSampler(samples_weight, size_data_augmented, replacement=True)\n\ntrain_augmented = train.iloc[list(augmented_sampler)]\n\n# Pie Chart\neff = list()\npercentage = list()\nfor i in range(5):\n    eff.append(len(train_augmented.iloc[np.where(train_augmented.iloc[:,1] == i)]))\n    percentage.append(round(100 * len(train_augmented.iloc[np.where(train_augmented.iloc[:,1] == i)]) / len(train_augmented)))\npalette = sns.color_palette('hls', n_colors = 5)\nplt.pie(eff, labels = ['0', '1', '2', '3', '4'], autopct = '%1.0f%%', colors = palette)\nplt.title('Proportion des différents stades de la maladie')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms # For image transformations.\n\nimport random\nclass BenColorTransform:\n    \"\"\" Ben filter explained below : we create a transform\"\"\"\n    def __init__(self, sigmaX=10, p = 0.25):\n        self.varX = sigmaX\n        self.prob = p\n    def __call__(self, image):\n        import random\n        x = random.randint(0,100)\n        if x <= self.prob*100:\n            image = cv2.addWeighted( image ,4, cv2.GaussianBlur( image , (0,0) , self.varX) ,-4 ,128)\n        return image\n\n# Transformations to apply to training image (normalize param based on imagenet, pytorch default).\naugmentation_transforms = transforms.Compose([BenColorTransform(sigmaX=10, p = 0.05), # Gaussian blur\n                                             transforms.ToPILImage(mode='RGB'),\n                                             \n                                             transforms.RandomHorizontalFlip(p=0.1), # Horizontally flip the given image randomly with a given probability.\n                                             transforms.RandomVerticalFlip(p=0.1), # Vertically flip the given image randomly with a given probability.\n                                             transforms.RandomInvert(p=0.1), # Inverts the colors of the given image randomly with a given probability.\n                                             transforms.RandomPosterize(bits=2, p=0.1), # Posterize the image randomly with a given probability by reducing the number of bits for each color channel.\n                                             transforms.RandomSolarize(threshold=192.0, p=0.1), # Solarize the image randomly with a given probability by inverting all pixel values above a threshold.\n                                             transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.1), # Adjust the sharpness of the image randomly with a given probability.\n                                             transforms.RandomAutocontrast(p=0.1), # Autocontrast the pixels of the given image randomly with a given probability.\n                                             transforms.RandomPerspective(distortion_scale=0.6, p=0.1), # Performs a random perspective transformation of the given image with a given probability.\n                                             \n                                             # RandomApply : Apply randomly a list of transformations with a given probability.\n                                             transforms.ToTensor(), # need tensor\n                                             \n                                             # Randomly change the brightness, contrast, saturation and hue of an image.\n                                             transforms.RandomApply([transforms.ColorJitter(brightness=.5, hue=.3)], p = 0.05),\n                                             # Crop a random portion of image and resize it to a given size.\n                                             transforms.RandomApply([transforms.RandomResizedCrop(256)], p = 0.1),\n                                             # Random affine transformation of the image keeping center invariant.\n                                             transforms.RandomApply([transforms.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.7, 0.9))], p = 0.1), \n                                             # Rotate the image by angle.\n                                             transforms.RandomApply([transforms.RandomRotation(degrees=(0, 180))], p = 0.1),\n                                             \n                                             transforms.CenterCrop(224),\n                                             transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) \n\n# Transformations to apply to test image (normalize param based on imagenet, pytorch default).\nbasic_transforms = transforms.Compose([transforms.ToPILImage(mode='RGB'),\n                                       transforms.CenterCrop(224),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Datasets","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader, SubsetRandomSampler #For working with data.\n\nclass EyeDataset(Dataset):\n    def __init__(self, \n                 df_from_csv,\n                 train = None, \n                 transform = None):\n        \n        self.data = df_from_csv\n        self.train = train\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        \n        # Find path and get the image\n        code = self.data['id_code'].values[idx]\n        if self.train : \n            datatype = \"train\"\n        else :\n            datatype = \"test\"\n        file_path = f'../input/aptos2019-blindness-detection/{datatype}_images/{code}.png'\n        img = cv2.imread(file_path)\n        \n        # Apply essential process : remove black + RGB\n        img = remove_black(img,tol=7) # Remove black\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # RGB\n        image = cv2.resize(img, (256, 256)) # Resize image to 256\n        image = self.transform(image)\n        \n        if self.train:\n            label = self.data['diagnosis'].values[idx]\n            return image, label\n        else :\n            return image, code\n        \nbatch_size = 64\nnum_workers = 0\n      \n###### Prepare data loaders with data augmentation\n\ndataset_augmented = EyeDataset(df_from_csv = train_augmented, \n                     train = True, \n                     transform = augmentation_transforms)\ndataset_validation = EyeDataset(df_from_csv = train_augmented, \n                     train = True, \n                     transform = basic_transforms)\n\ntr, val = train_test_split(train_augmented.diagnosis, stratify=train_augmented.diagnosis, test_size=0.2)\ntrain_sampler = SubsetRandomSampler(list(tr.index))\nvalid_sampler = SubsetRandomSampler(list(val.index))\n\ntrain_loader_augmented = DataLoader(dataset_augmented, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\nvalid_loader_augmented = DataLoader(dataset_validation, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n\n###### Prepare data test loaders (combine dataset and sampler)\n\ntest_set = EyeDataset(df_from_csv = test, \n                      train = False, \n                      transform = basic_transforms)\ntest_loader = DataLoader(test_set, batch_size=64, num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T23:36:04.099232Z","iopub.execute_input":"2022-04-18T23:36:04.099476Z","iopub.status.idle":"2022-04-18T23:36:04.118922Z","shell.execute_reply.started":"2022-04-18T23:36:04.099447Z","shell.execute_reply":"2022-04-18T23:36:04.11801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modèle","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #Use GPU if it's available or else use CPU.\nprint(device) #Prints the device we're using.","metadata":{"execution":{"iopub.status.busy":"2022-04-18T23:45:09.081486Z","iopub.execute_input":"2022-04-18T23:45:09.081771Z","iopub.status.idle":"2022-04-18T23:45:09.087059Z","shell.execute_reply.started":"2022-04-18T23:45:09.081739Z","shell.execute_reply":"2022-04-18T23:45:09.086135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import models # For template models\n\nmodel = models.resnet50(pretrained=True)\n\nnum_ftrs = model.fc.in_features # num_ftrs = 2048\nmodel.fc =  nn.Sequential(nn.Linear(num_ftrs, 5))\nmodel = model.to(device) #Moves the model to the device.","metadata":{"execution":{"iopub.status.busy":"2022-04-18T22:11:16.642516Z","iopub.execute_input":"2022-04-18T22:11:16.64279Z","iopub.status.idle":"2022-04-18T22:11:24.642891Z","shell.execute_reply.started":"2022-04-18T22:11:16.642754Z","shell.execute_reply":"2022-04-18T22:11:24.642178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def train(training_dataset, model, criterion, optimizer):\n    '''\n    train function updates the weights of the model based on the\n    loss using the optimizer in order to get a lower loss.\n    \n    Args :\n         training_dataset: Iterator for the batches in the data_set.\n         model: Given an input produces an output by multiplying the input with the model weights.\n         criterion: Calculates the discrepancy between the label & the model's predictions.\n         optimizer: Updates the model weights.\n         \n    Returns :\n         Average loss per batch which is calculated by dividing the losses for all the batches\n         with the number of batches.\n    '''\n    model.train() #Sets the model for training\n    \n    running_losses = [] # Vector of losses -> mean = average loss\n    \n    for (inputs, labels) in training_dataset:\n        # get the inputs; batch is a list of [inputs, labels]\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # zero the parameter gradients\n        optimizer.zero_grad()\n        \n        # forward + backward + optimize\n        out = model(inputs)\n        loss = criterion(out, labels)\n        loss.backward() #Calculates the gradients.\n        optimizer.step() #Updates the model weights.\n        \n        running_losses.append(loss.item())\n        \n    avg_loss = np.mean(running_losses) # Average loss for a single batch\n    print(f'\\nTraining Loss = {avg_loss:.6f}',end='\\t')\n    return avg_loss","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate(validation_dataset, model, criterion, final_layer):\n    '''\n    validate function calculates the average loss per batch and the accuracy of the model's predictions.\n    \n    Args :\n         validation_dataset: Iterator for the batches in the data_set.\n         model: Given an input produces an output by multiplying the input with the model weights.\n         criterion : Calculates the discrepancy between the label & the model's predictions.\n         final_layer: from logits to prob (usually softmax)\n    \n    Returns :\n         Average loss per batch which is calculated by dividing the losses for all the batches\n         with the number of batches.\n    '''\n    \n    model.eval() #Sets the model for evaluation.\n    \n    running_losses = [] # Vector of losses -> mean = average loss\n    \n    total = 0 # total of predictions\n    correct = 0 # total of correct predictions\n    \n    with torch.no_grad(): #No need to calculate the gradients.\n        \n        for (inputs, labels) in validation_dataset :\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs) #model's output.\n            running_losses.append(criterion(outputs, labels).item())\n            total += labels.size(0)\n            _, predicted = torch.max(final_layer(outputs).data, 1) # the class with the highest energy is what we choose as prediction\n            correct += (predicted == labels).sum().item()\n            \n    avg_loss = np.mean(running_losses) #Average loss per batch.\n    accuracy = 100*(correct/total)\n    \n    print(f'\\nValidation Loss = {avg_loss:.6f}',end='\\t')\n    print(f'Accuracy on Validation set = {accuracy:.6f}') #Prints the Accuracy.\n    \n    return avg_loss, accuracy","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\n# Scoring functions\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score\n\ndef optimize(training_dataset, validation_dataset, model, criterion, optimizer, final_layer, nb_epochs, n_epoch_no_change = 3):\n    '''\n    optimize function calls the train & validate functions for (nb_epochs) times.\n    \n    Args :\n        training_dataset: DataLoader for the train_set.\n        validation_dataset: DataLoader for the valid_set.\n        model: Given an input produces an output by multiplying the input with the model weights.\n        criterion: Calculates the discrepancy between the label & the model's predictions.\n        optimizer: Updates the model weights.\n        final_layer: from logits to prob (usually softmax)\n        nb_epochs: Number of epochs.\n        \n    Returns :\n        Tuple of lists containing losses, accuracies for all the epochs + kaggle score\n    '''\n    #Lists to store losses for all the epochs.\n    train_losses = []\n    valid_losses = []\n    valid_accuracies = []\n    \n    # Early stopping\n    iter_wout_change = 0\n    stop = 0\n    \n    for epoch in tqdm(range(nb_epochs)):\n        train_loss = train(training_dataset, model, criterion, optimizer) #Calls the train function.\n        train_losses.append(train_loss)\n        valid_loss, valid_accuracy = validate(validation_dataset, model, criterion, final_layer) #Calls the validate function.\n        valid_losses.append(valid_loss)\n        valid_accuracies.append(valid_accuracy)\n        print('| Epoch: {}/{} | Train: Loss {:.4f} '\\\n              '| Val: Loss {:.4f} Accuracy : {:.4f}\\n'.format(epoch+1, nb_epochs, train_losses[epoch], valid_losses[epoch], valid_accuracies[epoch]))\n        if valid_loss==min(valid_losses):\n            torch.save(model.state_dict(), 'model.param')\n            iter_wout_change = 0\n        else : \n            iter_wout_change += 1\n            if iter_wout_change == n_epoch_no_change : # If no improve in n_epoch_no_change epochs\n                stop = 1\n        if stop : \n            break # end of training\n    \n    print('\\nTraining has completed!')\n    \n    model.load_state_dict(torch.load('model.param')) # save best parameters according to validation loss\n    \n    print(\"################ Following : Losses & Accuracy ################## \")\n    \n    plt.semilogy(valid_accuracies)\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.title('Accuracy along the epochs')\n    plt.show()\n    \n    plt.semilogy(train_losses, label='Training loss') \n    plt.semilogy(valid_losses, label='Validation loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Losses')\n    plt.title('Losses comparison : Training vs Evaluation')\n    plt.legend()\n    plt.show()\n    \n    print(\"################ Performance : Accuracy, Confusion Matrix ################## \")\n    \n    model.eval() #Sets the model for evaluation.\n    labels_pred = [] #List to store the predicted labels.\n    labels_actual = [] #List to store the real labels.\n    with torch.no_grad():\n        for (inputs, labels) in validation_dataset:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs) #model's output.\n                        \n            _, predicted = torch.max(final_layer(outputs).data, 1) # the class with the highest energy is what we choose as prediction\n            labels_pred.extend([p.item() for p in predicted])\n            labels_actual.extend([l.item() for l in labels])\n    \n    matrix = confusion_matrix(labels_pred, labels_actual)\n    score = accuracy_score(labels_pred, labels_actual)\n    #plt.figure(figsize=(9,9))\n    sns.heatmap(matrix, annot = True, fmt = \".3f\", linewidths = .5, square = True, cmap = 'Blues_r');\n    plt.ylabel('Actual label');\n    plt.xlabel('Predicted label');\n    plt.title('Accuracy Score: {0}'.format(score), size = 15);\n    plt.show()\n    print(\"Accuracy by classes :\", matrix.diagonal()/matrix.sum(axis=1))\n    kaggle_score = cohen_kappa_score(labels_pred, labels_actual)\n    print(\"Kaggle score on validation set :\", kaggle_score)\n    \n    return train_losses, valid_losses, valid_accuracies, kaggle_score","metadata":{"execution":{"iopub.execute_input":"2022-04-05T15:46:00.482746Z","iopub.status.busy":"2022-04-05T15:46:00.482481Z","iopub.status.idle":"2022-04-05T15:55:26.818476Z","shell.execute_reply":"2022-04-05T15:55:26.81749Z","shell.execute_reply.started":"2022-04-05T15:46:00.482716Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Training of ResNet50 model (with data augmentation)\n\nimport torch.optim as optim\n\noutput_fn = torch.nn.Softmax(dim=1) # final_layer\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nlosst, lossv, accuracyv, kaggle = optimize(train_loader_augmented, valid_loader_augmented, model, criterion, optimizer, output_fn, nb_epochs = 10, n_epoch_no_change = 3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"We are going to submit the best model : ResNet50. With a Cohen Kappa score equal to :\", kaggle )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submissions","metadata":{}},{"cell_type":"code","source":"def make_submission(model_submitted, test_dataset, final_layer):\n    \n    submission = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\n    model_submitted.eval()\n    all_names = []\n    labels_pred = []\n    \n    for (batch) in test_dataset:\n        inputs, names = batch\n        all_names.extend(list(names))\n        \n        outputs = model_submitted(inputs.to(device)) #model's output.\n        _, predicted = torch.max(final_layer(outputs).data, 1) # the class with the highest energy is what we choose as prediction\n        labels_pred.extend([p.item() for p in predicted])\n        \n    list_diagno_name = list(zip(labels_pred, all_names))\n    for (diagno, name) in list_diagno_name:\n        submission.loc[submission['id_code'] == name, 'diagnosis'] = diagno\n    \n    submission.to_csv('submission.csv', index=False)\n    return submission\n\nsubmission = make_submission(model, test_loader, output_fn)\nprint(submission['diagnosis'].value_counts())\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T23:58:03.926966Z","iopub.execute_input":"2022-04-18T23:58:03.92722Z","iopub.status.idle":"2022-04-18T23:58:03.949415Z","shell.execute_reply.started":"2022-04-18T23:58:03.927192Z","shell.execute_reply":"2022-04-18T23:58:03.948508Z"},"trusted":true},"execution_count":null,"outputs":[]}]}